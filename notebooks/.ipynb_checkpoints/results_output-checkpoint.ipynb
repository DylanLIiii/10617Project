{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "import os \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import numpy as np \n",
    "import logging \n",
    "from termcolor import colored\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class MLPEncoderBlock(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, latent_dim, activation=nn.ReLU()):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            input_dim (_type_): _description_\n",
    "            hidden_dims (_type_): _description_\n",
    "            latent_dim (_type_): _description_\n",
    "            activation (_type_, optional): _description_. Defaults to nn.ReLU(). Use nn.Identity() for linear activation.\n",
    "        \"\"\"\n",
    "        super(MLPEncoderBlock, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.latent_dim = latent_dim\n",
    "        self.activation = activation\n",
    "        self.mlp = nn.ModuleList()\n",
    "        self.mlp.append(nn.Linear(self.input_dim, self.hidden_dims[0]))\n",
    "        for i in range(1, len(self.hidden_dims)):\n",
    "            self.mlp.append(nn.Linear(self.hidden_dims[i-1], self.hidden_dims[i]))\n",
    "        self.latent_map = nn.Linear(self.hidden_dims[-1], self.latent_dim)\n",
    "    \n",
    "    def forward(self, x): \n",
    "        x = self.mlp[0](x)\n",
    "        x = self.activation(x)\n",
    "        for i in range(1, len(self.mlp)):\n",
    "            x = self.mlp[i](x)\n",
    "            x = self.activation(x)\n",
    "        x = self.latent_map(x)\n",
    "        return x\n",
    "        \n",
    "class MLPDecoderBlock(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dims, output_dim, activation=nn.ReLU()):\n",
    "        super(MLPDecoderBlock, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.output_dim = output_dim\n",
    "        self.activation = activation\n",
    "        self.mlp = nn.ModuleList()\n",
    "        self.mlp.append(nn.Linear(self.latent_dim, self.hidden_dims[0]))\n",
    "        for i in range(1, len(self.hidden_dims)):\n",
    "            self.mlp.append(nn.Linear(self.hidden_dims[i-1], self.hidden_dims[i]))\n",
    "        self.output_map = nn.Linear(self.hidden_dims[-1], self.output_dim)\n",
    "    \n",
    "    def forward(self, z): \n",
    "        z = self.mlp[0](z)\n",
    "        z = self.activation(z)\n",
    "        for i in range(1, len(self.mlp)):\n",
    "            z = self.mlp[i](z)\n",
    "            z = self.activation(z)\n",
    "        z = self.output_map(z)\n",
    "        return z\n",
    "    \n",
    "    \n",
    "class CNNEncoderBlock(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, latent_dim, kernel_sizes, strides, paddings, activation=nn.ReLU()) -> None:\n",
    "        super().__init__()\n",
    "        self.activation = activation \n",
    "        self.conv = nn.ModuleList()\n",
    "        self.input_channels = input_channels\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.strides = strides\n",
    "        self.paddings = paddings\n",
    "        self.conv.append(nn.Sequential(nn.Conv2d(self.input_channels, self.hidden_channels[0], self.kernel_sizes[0], self.strides[0], self.paddings[0]),\n",
    "                                    self.activation,\n",
    "                                    nn.MaxPool2d(2, 2)))\n",
    "        for i in range(1, len(self.hidden_channels)):\n",
    "            self.conv.append(nn.Sequential(nn.Conv2d(self.hidden_channels[i-1], self.hidden_channels[i], self.kernel_sizes[i], self.strides[i], self.paddings[i]),\n",
    "                                    self.activation,\n",
    "                                    nn.MaxPool2d(2, 2)))\n",
    "        self.latent_mlp = nn.Linear(84, self.latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv[0](x)\n",
    "        #print(f\"Encode 0 {x.size()}\")\n",
    "        for i in range(1, len(self.conv)):\n",
    "            x = self.conv[i](x)\n",
    "            #print(f\"Encode {i, x.size()}\")\n",
    "        x = x.view(x.size(0), -1)\n",
    "        self.input_latent_dim = x.size(1)\n",
    "        x = self.latent_mlp(x)\n",
    "        return x\n",
    "    \n",
    "class CNNDecoderBlock(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_channels, output_channels, kernel_sizes, strides, paddings, activation=nn.ReLU()) -> None:\n",
    "        super().__init__()\n",
    "        self.activation = activation \n",
    "        self.conv = nn.ModuleList()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.strides = strides\n",
    "        self.paddings = paddings\n",
    "        # self.conv.append(nn.Sequential(nn.ConvTranspose2d(self.latent_dim, self.hidden_channels[0], self.kernel_sizes[0], self.strides[0], self.paddings[0]),self.activation))\n",
    "        for i in range(1, len(self.hidden_channels)):\n",
    "            self.conv.append(nn.Sequential(self.activation,\n",
    "                                        nn.ConvTranspose2d(self.hidden_channels[i-1], self.hidden_channels[i], self.kernel_sizes[i], self.strides[i], self.paddings[i]),))\n",
    "        self.conv.append(nn.Sequential(self.activation,\n",
    "                                    nn.ConvTranspose2d(self.hidden_channels[-1], self.output_channels, self.kernel_sizes[-1], self.strides[-1], self.paddings[-1])))\n",
    "        \n",
    "        if self.latent_dim == 2: \n",
    "            self.latent_mlp = nn.Linear(1, 84)\n",
    "        else:\n",
    "            self.latent_mlp = nn.Linear(self.latent_dim, 84)\n",
    "    def forward(self, z):\n",
    "        z = self.latent_mlp(z)\n",
    "        z = z.view(z.size(0), self.hidden_channels[0], 7, 3)\n",
    "        \n",
    "        z = F.interpolate(z, size=(15,7), mode='nearest')\n",
    "        z = self.conv[0](z)\n",
    "        #rint(f\"Decode: {0 , z.size()}\")\n",
    "        \n",
    "        z = F.interpolate(z, size=(31, 15), mode='nearest')\n",
    "        z = self.conv[1](z)\n",
    "        #print(f\"Decode: {1 , z.size()}\")\n",
    "        \n",
    "        z = F.interpolate(z, size=(62, 31), mode='nearest')\n",
    "        z = self.conv[2](z)\n",
    "        #print(f\"Decode: {2 , z.size()}\")\n",
    "        \n",
    "        z = F.interpolate(z, size=(125, 62), mode='nearest') # Not reverse of maxpooling. Generally upsampling is done by interpolation.\n",
    "        z = self.conv[3](z)\n",
    "        #print(f\"Decode: {3 , z.size()}\")\n",
    "        \n",
    "        z = F.interpolate(z, size=(250, 125), mode='nearest')\n",
    "        z = self.conv[4](z)\n",
    "        #print(f\"Decode: {4 , z.size()}\")\n",
    "        \n",
    "        z = F.interpolate(z, size=(501, 251), mode='nearest')\n",
    "        z = self.conv[5](z)\n",
    "        #print(f\"Decode: {5 , z.size()}\")\n",
    "        return z\n",
    "    \n",
    "    \n",
    "class DeepMatrixBlcok(nn.Module):\n",
    "    def __init__(self, latent_dim, constant_dim, deepth) -> None: \n",
    "        super(DeepMatrixBlcok, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.constant_dim = constant_dim\n",
    "        self.deepth = deepth\n",
    "        self.matrix = nn.ModuleList()\n",
    "        for i in range(self.deepth):\n",
    "            if i == 0: \n",
    "                self.matrix.append(nn.Linear(self.latent_dim, self.constant_dim))\n",
    "            self.matrix.append(nn.Linear(self.constant_dim, self.constant_dim))\n",
    "        self.final_layer  = nn.Linear(self.constant_dim, self.latent_dim)\n",
    "    def forward(self, x):\n",
    "        x = self.matrix[0](x)\n",
    "        for i in range(1, self.deepth):\n",
    "            x = self.matrix[i](x)\n",
    "        x = self.final_layer(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class CNNAutoEncoder(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels=[16, 8, 8, 8, 4, 4], latent_dim=5, kernel_sizes=[3, 3, 3, 3, 3, 3], strides=[1,1,1,1,1,1], paddings=[1,1,1,1,1,1], activation=nn.Tanh()):\n",
    "        super().__init__()\n",
    "        self.encoder = CNNEncoderBlock(input_channels, hidden_channels, latent_dim, kernel_sizes, strides, paddings, activation)\n",
    "        self.decoder = CNNDecoderBlock(latent_dim, hidden_channels[::-1], input_channels, kernel_sizes[::-1], strides[::-1], paddings[::-1], activation)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.encoder.latent_dim == 2:\n",
    "            z = self.encoder(x)\n",
    "            z1 = z[:, 0].unsqueeze(1)\n",
    "            z2 = z[:, 1].unsqueeze(1)\n",
    "            x1 = self.decoder(z1)\n",
    "            x2 = self.decoder(z2)\n",
    "            x_hat = x1 + x2 \n",
    "        else:\n",
    "            z = self.encoder(x)\n",
    "            x_hat = self.decoder(z)\n",
    "        return x_hat, z \n",
    "    \n",
    "    \n",
    "    \n",
    "class MLPAutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[512, 256, 128, 64], latent_dim=5, activation=nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.encoder = MLPEncoderBlock(input_dim, hidden_dims, latent_dim, activation)\n",
    "        self.decoder = MLPDecoderBlock(latent_dim, hidden_dims[::-1], input_dim, activation)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat, z\n",
    "    \n",
    "    \n",
    "class MLPAutoEncoderWithDeepMatrix(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[512, 256, 128, 64], latent_dim=5, activation=nn.ReLU(), deepth=3):\n",
    "        super().__init__()\n",
    "        self.encoder = MLPEncoderBlock(input_dim, hidden_dims, latent_dim, activation)\n",
    "        self.decoder = MLPDecoderBlock(latent_dim, hidden_dims[::-1], input_dim, activation)\n",
    "        self.deep_matrix = DeepMatrixBlcok(latent_dim, latent_dim, deepth)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        z = self.deep_matrix(z)\n",
    "        x = self.decoder(z)\n",
    "        return x, z\n",
    "    \n",
    "    \n",
    "class CNNAutoEncoderWithDeepMatrix(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels=[16, 8, 8, 8, 4, 4], latent_dim=5, kernel_sizes=[3, 3, 3, 3, 3, 3], strides=[1,1,1,1,1,1], paddings=[1,1,1,1,1,1], activation=nn.Tanh(), deepth=5):\n",
    "        super().__init__()\n",
    "        self.encoder = CNNEncoderBlock(input_channels, hidden_channels, latent_dim, kernel_sizes, strides, paddings, activation)\n",
    "        self.decoder = CNNDecoderBlock(latent_dim, hidden_channels[::-1], input_channels, kernel_sizes[::-1], strides[::-1], paddings[::-1], activation)\n",
    "        self.deep_matrix = DeepMatrixBlcok(latent_dim, latent_dim, deepth)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        z = self.deep_matrix(z)\n",
    "        x = self.decoder(z)\n",
    "        return x, z\n",
    "    \n",
    "    \n",
    "def reparameterize(mu, std):\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps*std\n",
    "    \n",
    "    \n",
    "class CNNVAE(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels=[16, 8, 8, 8, 4, 4], latent_dim=5, kernel_sizes=[3, 3, 3, 3, 3, 3], strides=[1,1,1,1,1,1], paddings=[1,1,1,1,1,1], activation=nn.Tanh()):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = CNNEncoderBlock(input_channels, hidden_channels, latent_dim * 2, kernel_sizes, strides, paddings, activation)\n",
    "        self.decoder = CNNDecoderBlock(latent_dim, hidden_channels[::-1], input_channels, kernel_sizes[::-1], strides[::-1], paddings[::-1], activation)\n",
    "        self.scaler =  Scaler()\n",
    "        self.mean_norm = nn.BatchNorm1d(latent_dim, affine=False, eps=1e-8)\n",
    "        self.std_norm = nn.BatchNorm1d(latent_dim, affine=False, eps=1e-8)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "    \n",
    "        mu = z[:, :self.latent_dim]\n",
    "        logvar = z[:, self.latent_dim:]\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        z_bar = reparameterize(mu, std)\n",
    "        x = self.sigmoid(self.decoder(z_bar))\n",
    "        return x, z_bar, mu, logvar\n",
    "    \n",
    "class CNNVAEWithDeepMatrix(nn.Module):\n",
    "    def __init__(self, args, input_channels, hidden_channels=[16, 8, 8, 8, 4, 4], latent_dim=5, kernel_sizes=[3, 3, 3, 3, 3, 3], strides=[1,1,1,1,1,1], paddings=[1,1,1,1,1,1], activation=nn.Tanh(), deepth=5):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = CNNEncoderBlock(input_channels, hidden_channels, latent_dim * 2, kernel_sizes, strides, paddings, activation)\n",
    "        self.decoder = CNNDecoderBlock(latent_dim, hidden_channels[::-1], input_channels, kernel_sizes[::-1], strides[::-1], paddings[::-1], activation)\n",
    "        self.deep_matrix = DeepMatrixBlcok(latent_dim, latent_dim, deepth)\n",
    "        self.scaler =  Scaler()\n",
    "        self.mean_norm = nn.BatchNorm1d(latent_dim, affine=False, eps=1e-8)\n",
    "        self.std_norm = nn.BatchNorm1d(latent_dim, affine=False, eps=1e-8)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        if self.args.vae_bn == 1:\n",
    "            # BN\n",
    "            mu = z[:, :self.latent_dim]\n",
    "            mu = self.mean_norm(mu)\n",
    "            mu = self.scaler(mu)\n",
    "            logvar = z[:, self.latent_dim:]\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            std = self.scaler(std)\n",
    "            std = self.std_norm(std)\n",
    "            z_bar = reparameterize(mu, std)\n",
    "        else: \n",
    "            mu = z[:, :self.latent_dim]\n",
    "            logvar = z[:, self.latent_dim:]\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            z_bar = reparameterize(mu, std)\n",
    "        x = self.sigmoid(self.decoder(z_bar))\n",
    "        return x, z_bar, mu, logvar\n",
    "    \n",
    "class MLPVAE(nn.Module):\n",
    "    def __init__(self, args, input_dim, hidden_dims=[512, 256, 128, 64], latent_dim=5, activation=nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = MLPEncoderBlock(input_dim, hidden_dims, latent_dim * 2, activation)\n",
    "        self.decoder = MLPDecoderBlock(latent_dim, hidden_dims[::-1], input_dim, activation)\n",
    "        self.scaler =  Scaler()\n",
    "        self.mean_norm = nn.BatchNorm1d(latent_dim, affine=False, eps=1e-8)\n",
    "        self.std_norm = nn.BatchNorm1d(latent_dim, affine=False, eps=1e-8)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        \n",
    "        if self.args.vae_bn == 1:\n",
    "            # BN\n",
    "            mu = z[:, :self.latent_dim]\n",
    "            mu = self.mean_norm(mu)\n",
    "            mu = self.scaler(mu)\n",
    "            logvar = z[:, self.latent_dim:]\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            std = self.scaler(std)\n",
    "            std = self.std_norm(std)\n",
    "            z_bar = reparameterize(mu, std)\n",
    "        else: \n",
    "            mu = z[:, :self.latent_dim]\n",
    "            logvar = z[:, self.latent_dim:]\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            z_bar = reparameterize(mu, std)\n",
    "        x = self.sigmoid(self.decoder(z_bar))\n",
    "        return x, z_bar, mu, logvar\n",
    "    \n",
    "class MLPVAEWithDeepMatrix(nn.Module):\n",
    "    def __init__(self, args, input_dim, hidden_dims=[512, 256, 128, 64], latent_dim=5, activation=nn.ReLU(), deepth=5):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = MLPEncoderBlock(input_dim, hidden_dims, latent_dim * 2, activation)\n",
    "        self.decoder = MLPDecoderBlock(latent_dim, hidden_dims[::-1], input_dim, activation)\n",
    "        self.deep_matrix = DeepMatrixBlcok(latent_dim, latent_dim, deepth)\n",
    "        self.scaler =  Scaler()\n",
    "        self.mean_norm = nn.BatchNorm1d(latent_dim, affine=False, eps=1e-8)\n",
    "        self.std_norm = nn.BatchNorm1d(latent_dim, affine=False, eps=1e-8)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        \n",
    "        if self.args.vae_bn == 1:\n",
    "            # BN\n",
    "            mu = z[:, :self.latent_dim]\n",
    "            mu = self.mean_norm(mu)\n",
    "            mu = self.scaler(mu)\n",
    "            logvar = z[:, self.latent_dim:]\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            std = self.scaler(std)\n",
    "            std = self.std_norm(std)\n",
    "            z_bar = reparameterize(mu, std)\n",
    "        else: \n",
    "            mu = z[:, :self.latent_dim]\n",
    "            logvar = z[:, self.latent_dim:]\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            z_bar = reparameterize(mu, std)\n",
    "        x = self.sigmoid(self.decoder(z_bar))\n",
    "        return x, z_bar, mu, logvar\n",
    "    \n",
    "class Scaler(nn.Module):\n",
    "    \"\"\"Special scale layer\"\"\"\n",
    "    def __init__(self, tau=0.5):\n",
    "        super(Scaler, self).__init__()\n",
    "        self.tau = tau\n",
    "        \n",
    "\n",
    "    def forward(self, inputs, mode='positive'):\n",
    "        self.scale = nn.Parameter(torch.zeros(inputs.shape[-1]))\n",
    "        if mode == 'positive':\n",
    "            scale = self.tau + (1 - self.tau) * torch.sigmoid(self.scale)\n",
    "        else:\n",
    "            scale = (1 - self.tau) * torch.sigmoid(-self.scale)\n",
    "        return inputs * torch.sqrt(scale).to(inputs.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['z_hat_MLPAutoEncoder_Fourth_version_running_20.npy',\n",
       " 'z_hat_MLPAutoEncoder_Fourth_version_running_5.npy',\n",
       " 'z_hat_MLPVAE_Second_version_running.npy',\n",
       " 'z_hat_MLPAutoEncoder_Fourth_version_running_10.npy',\n",
       " 'z_hat_MLPAutoEncoderWithDeepMatrix_Third_version_running_5.npy',\n",
       " 'z_hat_MLPAutoEncoder_Third_version_running_10.npy',\n",
       " 'z_hat_MLPAutoEncoderWithDeepMatrix_Fourth_version_running_10.npy',\n",
       " 'z_hat_MLPAutoEncoderWithDeepMatrix_Third_version_running_10.npy',\n",
       " 'z_hat_MLPAutoEncoder_Third_version_running_5.npy',\n",
       " 'z_hat_CNNAutoEncoder_Third_version_running_5.npy',\n",
       " 'z_hat_MLPAutoEncoderWithDeepMatrix_Fourth_version_running_20.npy',\n",
       " 'z_hat_MLPAutoEncoder_Second_version_running.npy',\n",
       " 'z_hat_CNNVAE_Second_version_running.npy',\n",
       " 'z_hat_CNNAutoEncoderWithDeepMatrix_Third_version_running_10.npy',\n",
       " 'z_hat_CNNAutoEncoder_Third_version_running_10.npy',\n",
       " 'z_hat_CNNVAEWithDeepMatrix_None.npy',\n",
       " 'z_hat_CNNAutoEncoderWithDeepMatrix_Third_version_running_20.npy',\n",
       " 'z_hat_MLPAutoEncoderWithDeepMatrix_Third_version_running_20.npy',\n",
       " 'z_hat_CNNVAEWithDeepMatrix_Second_version_running.npy',\n",
       " 'z_hat_CNNVAEWithDeepMatrix_test.npy',\n",
       " 'z_hat_MLPAutoEncoderWithDeepMatrix_Fourth_version_running_5.npy',\n",
       " 'z_hat_CNNAutoEncoderWithDeepMatrix_Second_version_running.npy',\n",
       " 'z_hat_CNNAutoEncoder_Second_version_running.npy',\n",
       " 'z_hat_MLPAutoEncoder_Third_version_running_20.npy',\n",
       " 'z_hat_CNNAutoEncoder_Third_version_running_20.npy',\n",
       " 'z_hat_CNNAutoEncoderWithDeepMatrix_Third_version_running_5.npy']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/home/dylan/repo/10617Project/results/physical/latent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_latents = {}\n",
    "CNN_latents = {}\n",
    "\n",
    "for latent in os.listdir('/home/dylan/repo/10617Project/results/physical/latent'):\n",
    "    if 'Second' in latent:\n",
    "        if 'MLP' in latent: \n",
    "            latent_npy = np.load(os.path.join('/home/dylan/repo/10617Project/results/physical/latent/' + latent))\n",
    "            MLP_latents[f'{latent}'] = latent_npy\n",
    "        elif 'CNN' in latent:\n",
    "            latent_npy = np.load(os.path.join('/home/dylan/repo/10617Project/results/physical/latent/' + latent))\n",
    "            CNN_latents[f'{latent}'] = latent_npy\n",
    "    else:\n",
    "        pass \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'z_hat_MLPAutoEncoder_Second_version_running.npy': array([[ 0.06912684,  0.19070265, -0.8326901 , -0.13067594, -0.6201942 ],\n",
      "       [ 0.06912532,  0.19065323, -0.8324493 , -0.13059732, -0.620104  ],\n",
      "       [ 0.06912368,  0.19060406, -0.8322009 , -0.13051692, -0.62000793],\n",
      "       ...,\n",
      "       [ 0.07112031,  0.0739127 , -0.83280134, -0.04967465, -0.73896956],\n",
      "       [ 0.07158013,  0.07692154, -0.83421123, -0.05104061, -0.73581237],\n",
      "       [ 0.07196378,  0.07987519, -0.83548963, -0.05242565, -0.73273593]],\n",
      "      dtype=float32),\n",
      " 'z_hat_MLPVAE_Second_version_running.npy': array([[-1.6492418 ,  0.29427665, -1.7034049 , -2.1959467 ,  0.1573792 ],\n",
      "       [ 1.0283587 ,  1.0004007 ,  0.82660806, -2.678462  , -0.8753331 ],\n",
      "       [-1.5513854 ,  1.8384391 , -0.55765355, -1.9541132 ,  0.39142436],\n",
      "       ...,\n",
      "       [ 1.245488  ,  0.06380814, -0.49246067,  0.20728314, -1.4044887 ],\n",
      "       [-0.23306157,  0.23600164,  0.7268009 , -0.26324308,  1.1600281 ],\n",
      "       [ 1.9098535 , -0.2463259 ,  0.24737109, -0.5517334 ,  0.5101615 ]],\n",
      "      dtype=float32)}\n",
      "{'z_hat_CNNAutoEncoderWithDeepMatrix_Second_version_running.npy': array([[ 3.3688297 ,  3.7190933 , -1.9436324 , -6.409989  , -0.1458585 ],\n",
      "       [ 3.596482  ,  3.6894522 , -1.8430021 , -6.4478645 ,  0.08897281],\n",
      "       [ 3.7669609 ,  3.6707869 , -1.7708695 , -6.4813833 ,  0.26206666],\n",
      "       ...,\n",
      "       [ 1.9050897 ,  3.8564773 , -2.542464  , -6.0891924 , -1.6146288 ],\n",
      "       [ 2.0253868 ,  3.8552651 , -2.502337  , -6.1301537 , -1.501658  ],\n",
      "       [ 2.1620948 ,  3.857019  , -2.4596183 , -6.1812963 , -1.3757535 ]],\n",
      "      dtype=float32),\n",
      " 'z_hat_CNNAutoEncoder_Second_version_running.npy': array([[ 0.86170995, -0.29077706,  0.7688519 , -0.53306735, -0.70826733],\n",
      "       [ 0.81778145, -0.22490633,  0.721074  , -0.56900376, -0.60054505],\n",
      "       [ 0.73994523, -0.189186  ,  0.69452703, -0.5975654 , -0.4785285 ],\n",
      "       ...,\n",
      "       [ 0.58113164, -0.9976492 ,  1.5226586 , -0.10703692, -0.70546246],\n",
      "       [ 0.6673165 , -0.95475984,  1.418725  , -0.1464395 , -0.7733963 ],\n",
      "       [ 0.74852663, -0.89288163,  1.3150606 , -0.19494826, -0.83152014]],\n",
      "      dtype=float32),\n",
      " 'z_hat_CNNVAEWithDeepMatrix_Second_version_running.npy': array([[-0.1115945 , -0.12344587, -0.17977153, -0.09918998,  0.67121625],\n",
      "       [-0.11102122, -0.12454598, -0.1801441 , -0.09759399,  0.67193794],\n",
      "       [-0.11146575, -0.11941932, -0.17642471, -0.10386077,  0.6686306 ],\n",
      "       ...,\n",
      "       [-0.1107845 , -0.12057346, -0.17712407, -0.10143711,  0.6697451 ],\n",
      "       [-0.11220959, -0.12430929, -0.18050572, -0.09945419,  0.6713313 ],\n",
      "       [-0.1112788 , -0.11725295, -0.17464772, -0.10607213,  0.66736275]],\n",
      "      dtype=float32),\n",
      " 'z_hat_CNNVAE_Second_version_running.npy': array([[-0.64991415,  0.41526404, -0.92356294, -0.43444932, -0.05724213],\n",
      "       [ 0.52584195,  0.6164401 ,  0.06113071,  1.8297414 , -0.02161306],\n",
      "       [-0.04388587, -0.10032336,  0.3581619 , -1.6892842 ,  0.4385206 ],\n",
      "       ...,\n",
      "       [-0.78902835,  0.3518838 ,  0.5671101 , -0.90272367, -1.0557618 ],\n",
      "       [-0.07556111, -0.6074717 ,  0.44528204,  0.5495713 ,  1.0381967 ],\n",
      "       [-1.347383  , -0.9313329 , -0.31724486, -0.40384847,  0.38748464]],\n",
      "      dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(MLP_latents)\n",
    "pprint(CNN_latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mLoad data successfully\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Data = sio.loadmat('/home/dylan/repo/10617Project/data/physical/CYLINDER.mat')\n",
    "U = Data['U']\n",
    "V = Data['V']\n",
    "VORTALL = Data['VORTALL']\n",
    "X = Data['X']\n",
    "Y = Data['Y']\n",
    "Dx = Data['dx'].item()  \n",
    "Dy = Data['dy'].item()\n",
    "nx = Data['nx'].item()\n",
    "ny = Data['ny'].item()\n",
    "print(colored(\"Load data successfully\", 'green'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Phi_U, s_U, Vt_U = np.linalg.svd(U, False)\\n# Latent of MLPAE \\nMLPAE_Latent = MLP_latents['z_hat_MLPAutoEncoder_Second_version_running.npy']\\n# Latent of CNN\\nCNNAE_Latent = CNN_latents['z_hat_CNNAutoEncoder_Second_version_running.npy']\\n# Latent of CNNDM\\nCNNDM_Latent = CNN_latents['z_hat_CNNVAEWithDeepMatrix_Second_version_running.npy']\\n# Latent of CNNVAE\\nCNNVAE_Latent = CNN_latents['z_hat_CNNVAE_Second_version_running.npy']\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA, MLPAE, CNN, CNNDM, CNNVAE\n",
    "# Mode of PCA is Phi_U\n",
    "'''Phi_U, s_U, Vt_U = np.linalg.svd(U, False)\n",
    "# Latent of MLPAE \n",
    "MLPAE_Latent = MLP_latents['z_hat_MLPAutoEncoder_Second_version_running.npy']\n",
    "# Latent of CNN\n",
    "CNNAE_Latent = CNN_latents['z_hat_CNNAutoEncoder_Second_version_running.npy']\n",
    "# Latent of CNNDM\n",
    "CNNDM_Latent = CNN_latents['z_hat_CNNVAEWithDeepMatrix_Second_version_running.npy']\n",
    "# Latent of CNNVAE\n",
    "CNNVAE_Latent = CNN_latents['z_hat_CNNVAE_Second_version_running.npy']'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    def __init__(self):\n",
    "        self.latent_dim = 5\n",
    "        self.vae_bn = 0\n",
    "        self.vae = 0\n",
    "        self.deep_matrix = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model of CNN\n",
    "import torch\n",
    "CNN = CNNAutoEncoder(1, latent_dim=5, activation=nn.ReLU())\n",
    "CNN.load_state_dict(torch.load('/home/dylan/repo/10617Project/model/Final_CNNAE.pth'))\n",
    "# model of CNNDM\n",
    "CNNDM = CNNAutoEncoderWithDeepMatrix(1, latent_dim=5, activation=nn.ReLU(), deepth=8)\n",
    "CNNDM.load_state_dict(torch.load('/home/dylan/repo/10617Project/model/Final_CNNDM.pth'))\n",
    "# model of CNNVAE\n",
    "\n",
    "args = CONFIG()\n",
    "CNNVAE = CNNVAE(input_channels=1, latent_dim=args.latent_dim, activation=nn.ReLU())\n",
    "CNNVAE.load_state_dict(torch.load('/home/dylan/repo/10617Project/model/Final_CNNVAE.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching for Rank 1: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:09<00:00,  1.82s/mode]\n",
      "Searching for Rank 2: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:07<00:00,  1.45s/mode]\n",
      "Searching for Rank 3: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:05<00:00,  1.09s/mode]\n",
      "Searching for Rank 4: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:03<00:00,  1.37mode/s]\n",
      "Searching for Rank 5: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  2.74mode/s]\n"
     ]
    }
   ],
   "source": [
    "U = U.reshape(nx, ny, -1, 1).transpose(2, 3, 0, 1)\n",
    "U_max = np.inf\n",
    "U_min = -np.inf\n",
    "U = U.reshape(250,-1)\n",
    "U_max, U_min = np.max(U, axis=1).reshape(-1, 1), np.min(U, axis=1).reshape(-1, 1)\n",
    "U_std = (U - U_min)/ (U_max - U_min)\n",
    "U_scaled = U_std * (1 - 0) + 0\n",
    "#U_max, U_min, U_scaled_max, U_scaled_min  = np.max(U), np.min(U), np.max(U_scaled), np.min(U_scaled)\n",
    "\n",
    "U = U_scaled.reshape(250, 1, nx, ny)\n",
    "args.vae = 0\n",
    "args.deep_matrix = 0\n",
    "def rank_z(args, model, original_data):\n",
    "    \"\"\"\n",
    "    Use this function to rank the latent space. \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model = model.to('cpu')\n",
    "    # construct data\n",
    "    z = model.encoder(torch.Tensor(original_data))\n",
    "    if args.vae: \n",
    "        _, z, _, _  = model.forward(torch.Tensor(original_data))\n",
    "    if args.deep_matrix:\n",
    "        z = model.deep_matrix(z)\n",
    "    z = z.detach().cpu().numpy()\n",
    "    \n",
    "    num = args.latent_dim if args.latent_dim < 5 else 5\n",
    "\n",
    "    top_scores = [] \n",
    "    top_reconstruction = []\n",
    "    top_modes = []\n",
    "    prev_best = None \n",
    "    \n",
    "    for i in range(1, num+1):\n",
    "        current_best_score = None\n",
    "        current_best_combo = None\n",
    "        current_best_xhat = None\n",
    "        current_best_mode = None\n",
    "\n",
    "        for j in tqdm(range(int(z.shape[1])), desc=f'Searching for Rank {i}', unit='mode'):\n",
    "            if prev_best is None:\n",
    "                combo = (j,)\n",
    "            else:\n",
    "                if j in prev_best:\n",
    "                    continue\n",
    "                combo = prev_best + (j,)\n",
    "            z_i = np.zeros_like(z)\n",
    "            for index in combo:\n",
    "                z_i[:, index] = z[:, index]\n",
    "            x_hat = model.decoder(torch.Tensor(z_i))\n",
    "            x_hat = x_hat.detach().cpu().numpy()\n",
    "            # original energy\n",
    "            score = mse(x_hat.reshape(-1,250), original_data.reshape(-1,250))\n",
    "            # reconstruction energy\n",
    "            #score = cal_energy(model, original_data, combo, z, 1, 1)\n",
    "            if current_best_score is None or score < current_best_score:\n",
    "                current_best_score = score\n",
    "                current_best_combo = combo\n",
    "                current_best_xhat = x_hat\n",
    "                current_best_mode = z_i\n",
    "\n",
    "        top_scores.append((current_best_score, current_best_combo))\n",
    "        top_reconstruction.append(current_best_xhat)\n",
    "        top_modes.append(current_best_mode)\n",
    "        prev_best = current_best_combo\n",
    "\n",
    "    return z, top_scores, top_reconstruction, top_modes\n",
    "\n",
    "CNN_z, CNN_top_scores, CNN_top_reconstruction, CNN_top_modes = rank_z(args, CNN, U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.016960140323196753, (2,)),\n",
       " (0.011020909876683738, (2, 1)),\n",
       " (0.007127743089016355, (2, 1, 3)),\n",
       " (0.007593973079407842, (2, 1, 3, 4)),\n",
       " (0.0006239201095859049, (2, 1, 3, 4, 0))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_top_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching for Rank 1: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:09<00:00,  1.82s/mode]\n",
      "Searching for Rank 2: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:07<00:00,  1.59s/mode]\n",
      "Searching for Rank 3: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:05<00:00,  1.14s/mode]\n",
      "Searching for Rank 4: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:03<00:00,  1.32mode/s]\n",
      "Searching for Rank 5: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  2.65mode/s]\n"
     ]
    }
   ],
   "source": [
    "# For CNNDM \n",
    "args.vae = 0\n",
    "args.deep_matrix = 1\n",
    "CNNDM_z, CNNDM_top_scores, CNNDM_top_reconstruction, CNNDM_top_modes = rank_z(args, CNNDM, U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.02692854447078485, (3,)),\n",
       " (0.022001638849547256, (3, 0)),\n",
       " (0.010320803124061006, (3, 0, 1)),\n",
       " (0.005753017926410447, (3, 0, 1, 2)),\n",
       " (0.0032189204849668966, (3, 0, 1, 2, 4))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNNDM_top_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching for Rank 1: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:09<00:00,  1.89s/mode]\n",
      "Searching for Rank 2: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:07<00:00,  1.50s/mode]\n",
      "Searching for Rank 3: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:05<00:00,  1.13s/mode]\n",
      "Searching for Rank 4: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:03<00:00,  1.33mode/s]\n",
      "Searching for Rank 5: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  2.68mode/s]\n"
     ]
    }
   ],
   "source": [
    "# For CNNVAE\n",
    "args.vae = 1\n",
    "args.deep_matrix = 0\n",
    "CNNVAE_z, CNNVAE_top_scores, CNNVAE_top_reconstruction, CNNVAE_top_modes = rank_z(args, CNNVAE, U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_top_modes = [mode[220,:,:,:].reshape(1,1,nx,ny).transpose(2,3,0,1).reshape(nx*ny,-1) for mode in CNNDM_top_reconstruction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Together \n",
    "def plot_latent(z_list):\n",
    "  r = range(5)\n",
    "  fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(20,10))\n",
    "  v_min = 0\n",
    "  v_max = 1\n",
    "  for idx, z in zip(range(len(z_list)), z_list):\n",
    "    for i in r:\n",
    "      pcm = axs[i,idx].pcolormesh(X,Y,z[:,i].reshape(nx,ny).T, cmap = 'RdBu_r', vmin=v_min, vmax=v_max)\n",
    "      #fig.colorbar(pcm, ax=axs[i,idx]))\n",
    "      if idx == 0:\n",
    "        model_name = 'PCA'\n",
    "      elif idx == 1:\n",
    "        model_name = 'CNN'\n",
    "      elif idx == 2:\n",
    "        model_name = 'CNNDM'\n",
    "      elif idx == 3:\n",
    "        model_name = 'CNNVAE'\n",
    "      axs[i,idx].set_title(f'{model_name} mode {i+1}', fontsize=18)\n",
    "      axs[i,idx].set_aspect('equal')\n",
    "      axs[i,idx].set_xlabel('x', fontsize = 20)\n",
    "      axs[i,idx].set_ylabel('y', fontsize = 20)\n",
    "  cb = fig.colorbar(pcm, ax=axs.ravel().tolist())\n",
    "  cb.ax.tick_params(labelsize=18)\n",
    "  fig.savefig('/output/latent_modes.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aiml]",
   "language": "python",
   "name": "conda-env-aiml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
